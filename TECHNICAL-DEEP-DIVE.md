# Kupuri Studios - Technical Deep Dive: What Makes It Work

## ðŸ—ï¸ System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER BROWSER (React)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  HeroSection          ProjectCard        ThemeToggle         â”‚
â”‚  PricingPage          ProjectModal       Authentication       â”‚
â”‚                                                               â”‚
â”‚  State: Zustand/Context                                      â”‚
â”‚  Animations: Framer Motion                                   â”‚
â”‚  Styling: Tailwind CSS                                       â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
          HTTP REST + WebSocket
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            FASTAPI SERVER (Python)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  ROUTERS (Endpoints)                         â”‚             â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚  â”‚  â€¢ chat_router.py      (/api/chat)           â”‚             â”‚
â”‚  â”‚  â€¢ websocket_router.py (Socket.IO events)    â”‚             â”‚
â”‚  â”‚  â€¢ canvas.py           (/api/canvas)         â”‚             â”‚
â”‚  â”‚  â€¢ image_router.py     (/api/image)          â”‚             â”‚
â”‚  â”‚  â€¢ config_router.py    (/api/config)         â”‚             â”‚
â”‚  â”‚  â€¢ settings.py         (/api/settings)       â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                       â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  SERVICES (Business Logic)                   â”‚             â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚  â”‚  â€¢ chat_service.py                           â”‚             â”‚
â”‚  â”‚  â€¢ magic_service.py                          â”‚             â”‚
â”‚  â”‚  â€¢ websocket_service.py                      â”‚             â”‚
â”‚  â”‚  â€¢ db_service.py                             â”‚             â”‚
â”‚  â”‚  â€¢ tool_service.py                           â”‚             â”‚
â”‚  â”‚  â€¢ langgraph_service/                        â”‚             â”‚
â”‚  â”‚    â””â”€ agent_service.py (Multi-agent AI)      â”‚             â”‚
â”‚  â”‚    â””â”€ StreamProcessor.py (Real-time output)  â”‚             â”‚
â”‚  â”‚  â€¢ config_service.py                         â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                       â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  AI ORCHESTRATION                            â”‚             â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚  â”‚  LangGraph Multi-Agent Engine                â”‚             â”‚
â”‚  â”‚  â””â”€ Manages multiple AI models              â”‚             â”‚
â”‚  â”‚  â””â”€ Routes between GPT-4, Claude, etc.      â”‚             â”‚
â”‚  â”‚                                               â”‚             â”‚
â”‚  â”‚  Tool Execution                              â”‚             â”‚
â”‚  â”‚  â””â”€ ComfyUI for image generation             â”‚             â”‚
â”‚  â”‚  â””â”€ Flux for text-to-image                   â”‚             â”‚
â”‚  â”‚  â””â”€ Ollama for local LLMs                    â”‚             â”‚
â”‚  â”‚                                               â”‚             â”‚
â”‚  â”‚  Stream Processor                            â”‚             â”‚
â”‚  â”‚  â””â”€ Real-time token streaming                â”‚             â”‚
â”‚  â”‚  â””â”€ Progress updates to UI                   â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                       â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  PERSISTENCE LAYER                           â”‚             â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚  â”‚  SQLite Database (aiosqlite)                 â”‚             â”‚
â”‚  â”‚  â””â”€ Canvases                                 â”‚             â”‚
â”‚  â”‚  â””â”€ Chat Sessions & Messages                â”‚             â”‚
â”‚  â”‚  â””â”€ User Settings                            â”‚             â”‚
â”‚  â”‚  â””â”€ Tool Confirmations                       â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                       â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  EXTERNAL APIs                               â”‚             â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚  â”‚  OpenAI (GPT-4, GPT-3.5)                    â”‚             â”‚
â”‚  â”‚  Anthropic (Claude-3)                        â”‚             â”‚
â”‚  â”‚  Stripe (Payment Processing)                 â”‚             â”‚
â”‚  â”‚  ComfyUI (Local Image Generation)            â”‚             â”‚
â”‚  â”‚  Ollama (Local LLMs)                         â”‚             â”‚
â”‚  â”‚  MCP (Model Context Protocol)                â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”Œ Frontend-Backend Communication

### **Request/Response Flow**

#### **1. Chat Request (HTTP POST)**
```typescript
// Frontend (React)
const response = await fetch('/api/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    messages: [{ role: 'user', content: 'Generate an image...' }],
    session_id: 'sess_xyz',
    canvas_id: 'canvas_abc',
    text_model: { model: 'gpt-4', provider: 'openai' },
    tool_list: [{ model: 'flux', provider: 'comfyui' }],
    system_prompt: 'You are a helpful assistant'
  })
})
```

#### **2. Backend Processing (Python)**
```python
# Backend (chat_router.py)
@router.post("/api/chat")
async def chat(request: Request):
    data = await request.json()
    await handle_chat(data)  # Async task started
    return {"status": "done"}

# chat_service.py
async def handle_chat(data):
    # 1. Parse data
    messages = data.get('messages', [])
    session_id = data.get('session_id', '')
    
    # 2. Save to database
    await db_service.create_chat_session(...)
    await db_service.create_message(...)
    
    # 3. Launch AI agent task
    task = asyncio.create_task(
        langgraph_multi_agent(messages, canvas_id, session_id, ...)
    )
    
    # 4. Register for cancellation support
    add_stream_task(session_id, task)
```

#### **3. Real-Time Streaming (WebSocket)**
```python
# Stream processor sends updates during AI generation
async def stream_processor():
    while streaming:
        # Send token updates in real-time
        await send_to_websocket(session_id, {
            'type': 'token',
            'delta': 'The generated...',
            'index': 42
        })
        
# Frontend receives updates
socket.on('session_update', (data) => {
    if (data.type === 'token') {
        setOutput(prev => prev + data.delta)
    }
})
```

#### **4. Completion Signal (WebSocket)**
```python
# Backend signals completion
await send_to_websocket(session_id, {
    'type': 'done',
    'final_output': 'Complete AI response'
})

# Frontend receives completion
socket.on('session_update', (data) => {
    if (data.type === 'done') {
        setIsLoading(false)
    }
})
```

---

## ðŸ¤– AI Orchestration Engine

### **LangGraph Multi-Agent System**

```python
# langgraph_service/agent_service.py
async def langgraph_multi_agent(messages, canvas_id, session_id, text_model, tool_list):
    
    # 1. Create Language Model Instance
    if text_model['provider'] == 'openai':
        llm = ChatOpenAI(model="gpt-4", temperature=0.7)
    elif text_model['provider'] == 'anthropic':
        llm = ChatAnthropic(model="claude-3", temperature=0.7)
    
    # 2. Create Tool Instances (Image generation, etc.)
    tools = []
    for tool_config in tool_list:
        tool = create_tool(tool_config['model'], tool_config['provider'])
        tools.append(tool)
    
    # 3. Build Agent Graph
    agent_executor = create_swarm(
        llm=llm,
        tools=tools,
        system_prompt=system_prompt
    )
    
    # 4. Run Agent with Streaming
    async for event in agent_executor.stream_events(
        input={'messages': messages},
        config={'configurable': {'thread_id': session_id}}
    ):
        # Process each event
        if event.get('type') == 'on_chat_model_stream':
            token = event['data']['chunk'].content
            # Send to frontend via WebSocket
            await send_to_websocket(session_id, {
                'type': 'token',
                'delta': token
            })
        
        elif event.get('type') == 'on_tool_start':
            tool_name = event['data']['tool']
            # Notify UI tool is executing
            await send_to_websocket(session_id, {
                'type': 'tool_start',
                'tool': tool_name
            })
        
        elif event.get('type') == 'on_tool_end':
            result = event['data']['output']
            # Send tool result back
            await send_to_websocket(session_id, {
                'type': 'tool_result',
                'result': result
            })
```

### **Tool Routing Example**

```python
# User asks: "Generate an image of a sunset"

# 1. Text model (GPT-4) understands intent
# 2. Identifies need for image generation tool
# 3. Routes to Flux/ComfyUI tool
# 4. Flux executes with prompt parameters
# 5. Returns image URL
# 6. Final response sent to user

Message Flow:
User Input â†’ GPT-4 (reasoning) â†’ Flux Tool (execution) â†’ Image Result â†’ UI Display
```

---

## ðŸ’¾ Database Architecture

### **SQLite Schema**

```sql
-- Canvases (Projects)
CREATE TABLE canvases (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    thumbnail TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Chat Sessions
CREATE TABLE chat_sessions (
    id TEXT PRIMARY KEY,
    model TEXT NOT NULL,
    provider TEXT NOT NULL,
    canvas_id TEXT NOT NULL,
    title TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (canvas_id) REFERENCES canvases(id)
);

-- Chat Messages
CREATE TABLE chat_messages (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL,
    role TEXT NOT NULL,  -- 'user', 'assistant', 'tool'
    message TEXT NOT NULL,  -- JSON serialized message
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (session_id) REFERENCES chat_sessions(id)
);

-- Tool Confirmations (for user approval of tool execution)
CREATE TABLE tool_confirmations (
    id TEXT PRIMARY KEY,
    session_id TEXT NOT NULL,
    tool_name TEXT NOT NULL,
    params JSON NOT NULL,
    status TEXT DEFAULT 'pending',  -- pending, approved, rejected
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (session_id) REFERENCES chat_sessions(id)
);
```

### **Database Access (Async)**

```python
# services/db_service.py
async def create_canvas(self, id: str, name: str):
    """Create new canvas with async SQLite"""
    async with aiosqlite.connect(self.db_path) as db:
        await db.execute(
            "INSERT INTO canvases (id, name) VALUES (?, ?)",
            (id, name)
        )
        await db.commit()

async def get_chat_history(self, session_id: str):
    """Retrieve chat history with message parsing"""
    async with aiosqlite.connect(self.db_path) as db:
        db.row_factory = sqlite3.Row
        cursor = await db.execute(
            "SELECT role, message FROM chat_messages WHERE session_id = ? ORDER BY id ASC",
            (session_id,)
        )
        rows = await cursor.fetchall()
        
        # Parse JSON messages
        messages = []
        for row in rows:
            msg = json.loads(row['message'])
            messages.append(msg)
        return messages
```

---

## ðŸ”„ WebSocket Real-Time Communication

### **Connection Lifecycle**

```python
# services/websocket_router.py

@sio.event
async def connect(sid, environ, auth):
    """Client connects"""
    print(f"Client {sid} connected")
    user_info = auth or {}
    add_connection(sid, user_info)
    
    # Notify client they're connected
    await sio.emit('connected', {'status': 'connected'}, room=sid)

@sio.event
async def disconnect(sid):
    """Client disconnects"""
    print(f"Client {sid} disconnected")
    remove_connection(sid)

@sio.event
async def ping(sid, data):
    """Keepalive ping"""
    await sio.emit('pong', data, room=sid)
```

### **Broadcasting Updates**

```python
# services/websocket_service.py

async def send_to_websocket(session_id: str, event: Dict[str, Any]):
    """Send event to specific session subscribers"""
    socket_ids = get_all_socket_ids()
    
    for socket_id in socket_ids:
        await sio.emit('session_update', {
            'session_id': session_id,
            **event  # type: 'token', type: 'done', etc.
        }, room=socket_id)

# Frontend receives updates
useEffect(() => {
    socket.on('session_update', (data) => {
        if (data.session_id === currentSessionId) {
            if (data.type === 'token') {
                setResponse(prev => prev + data.delta)
            } else if (data.type === 'done') {
                setIsStreaming(false)
            }
        }
    })
}, [socket])
```

---

## ðŸ’° Monetization & Usage Tracking

### **Payment Intent Creation**

```typescript
// frontend - react/src/lib/stripe.ts
export async function createPaymentIntent(amount: number, userId: string) {
    const stripe = new Stripe(process.env.STRIPE_SECRET_KEY)
    
    const intent = await stripe.paymentIntents.create({
        amount: Math.round(amount * 100),  // Convert to cents
        currency: 'usd',
        metadata: { userId }
    })
    
    return intent
}
```

### **Usage Tracking**

```typescript
// Track each generation
export async function trackUsage(userId: string, model: string, count: number) {
    const PRICING = {
        'gpt-4': 0.50,
        'gpt-3.5': 0.10,
        'claude-3': 0.40,
        'flux': 0.05,
        'midjourney': 1.00
    }
    
    const cost = PRICING[model] * count
    
    // Save to database
    await db.create_usage_record({
        userId,
        model,
        count,
        cost,
        timestamp: new Date()
    })
    
    return { userId, model, count, cost }
}
```

---

## ðŸŽ¨ Frontend Component Architecture

### **Component Hierarchy**

```
App
â”œâ”€â”€ HeroSection
â”‚   â”œâ”€â”€ Parallax Scroll Effect
â”‚   â”œâ”€â”€ Animated Gradient Text
â”‚   â”œâ”€â”€ Staggered Text Animation
â”‚   â””â”€â”€ CTA Buttons
â”‚
â”œâ”€â”€ PricingPage
â”‚   â”œâ”€â”€ Pricing Tiers (3)
â”‚   â”‚   â”œâ”€â”€ Free ($0)
â”‚   â”‚   â”œâ”€â”€ Pay-As-You-Go (Most Popular)
â”‚   â”‚   â””â”€â”€ Pro Team (Custom)
â”‚   â”œâ”€â”€ Feature Comparison
â”‚   â””â”€â”€ FAQ Section
â”‚
â”œâ”€â”€ ProjectCard (Grid)
â”‚   â”œâ”€â”€ Image Blur-Up Loading
â”‚   â”œâ”€â”€ Hover Scale Animation
â”‚   â”œâ”€â”€ Overlay Text
â”‚   â””â”€â”€ View Project Indicator
â”‚
â”œâ”€â”€ ProjectModal
â”‚   â”œâ”€â”€ Spring Enter Animation
â”‚   â”œâ”€â”€ Hero Image Carousel
â”‚   â”œâ”€â”€ Tech Stack Badges
â”‚   â”œâ”€â”€ "Open Live Site" CTA
â”‚   â””â”€â”€ Focus Trap (Accessibility)
â”‚
â”œâ”€â”€ ThemeToggle
â”‚   â”œâ”€â”€ Sun/Moon Icons
â”‚   â””â”€â”€ Animated Switch
â”‚
â””â”€â”€ Chat Interface
    â”œâ”€â”€ Message List
    â”œâ”€â”€ Tool Execution Indicator
    â”œâ”€â”€ Streaming Token Display
    â””â”€â”€ Cancel Button
```

### **State Management (Zustand)**

```typescript
// Create store
const useStore = create((set) => ({
    // User state
    user: null,
    setUser: (user) => set({ user }),
    
    // Chat state
    messages: [],
    addMessage: (msg) => set(state => ({ 
        messages: [...state.messages, msg] 
    })),
    
    // UI state
    isLoading: false,
    setIsLoading: (loading) => set({ isLoading: loading }),
    
    // Theme state
    theme: 'dark',
    toggleTheme: () => set(state => ({ 
        theme: state.theme === 'dark' ? 'light' : 'dark' 
    }))
}))

// Use in component
const { messages, addMessage } = useStore()
```

---

## ðŸš€ Deployment: Docker Multi-Stage Build

### **Dockerfile Stages**

```dockerfile
# Stage 1: Build Frontend
FROM node:20-alpine as frontend-build
WORKDIR /app/react
COPY react/package*.json ./
RUN npm ci
COPY react/ .
RUN npm run build
# Output: /app/react/dist/

# Stage 2: Runtime Backend + Frontend
FROM python:3.12-slim
WORKDIR /app

# Install Python deps
COPY server/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy backend code
COPY server/ ./server/

# Copy built frontend from Stage 1
COPY --from=frontend-build /app/react/dist ./react/dist

# Set environment
ENV UI_DIST_DIR=/app/react/dist
ENV HOST=0.0.0.0
ENV PORT=8000

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/')" || exit 1

# Start server
CMD ["python", "server/main.py", "--port", "8000"]
```

### **What Gets Built**
```
Stage 1 (18 mins):
  node:20-alpine â†’ npm install â†’ npm run build â†’ dist/ (246 kB gzipped)

Stage 2 (3 mins):
  python:3.12-slim
  + server dependencies (FastAPI, LangGraph, Stripe, etc.)
  + copy built dist/ from Stage 1
  = Single 500MB Docker image
```

---

## ðŸ” Security & Authentication

### **Socket.IO Authentication**

```python
# Backend - Validate connection
@sio.event
async def connect(sid, environ, auth):
    """
    auth = {
        'token': 'jwt_token_xyz',
        'user_id': 'user_123'
    }
    """
    # Validate JWT token
    if not validate_jwt(auth.get('token')):
        raise ConnectionRefusedError('Invalid token')
    
    user_info = decode_jwt(auth['token'])
    add_connection(sid, user_info)

# Frontend - Send auth on connect
useEffect(() => {
    socket = io('http://localhost:8000', {
        auth: {
            token: localStorage.getItem('jwt_token'),
            user_id: user.id
        }
    })
    
    socket.connect()
}, [])
```

### **API Middleware**

```python
# Stripe webhook verification
@router.post("/api/stripe/webhook")
async def stripe_webhook(request: Request):
    payload = await request.body()
    sig_header = request.headers.get('stripe-signature')
    
    # Verify signature
    try:
        event = stripe.Webhook.construct_event(
            payload, sig_header, STRIPE_WEBHOOK_SECRET
        )
    except ValueError:
        return {"error": "Invalid payload"}, 400
    except stripe.error.SignatureVerificationError:
        return {"error": "Invalid signature"}, 400
    
    # Process event
    if event['type'] == 'payment_intent.succeeded':
        amount = event['data']['object']['amount']
        user_id = event['data']['object']['metadata']['user_id']
        
        # Update user balance
        await db_service.add_user_credit(user_id, amount / 100)
    
    return {"status": "ok"}
```

---

## ðŸ“Š Performance Optimizations

### **Frontend Optimizations**

```typescript
// 1. Image Blur-Up Loading (LQIP)
<img 
    src={projectImage}
    className={isLoaded ? 'blur-0' : 'blur-lg'}
    onLoad={() => setIsLoaded(true)}
/>

// 2. Code Splitting
const ProjectModal = lazy(() => import('./ProjectModal'))

// 3. Memoization
const ProjectCard = memo(({ project, onClick }) => {
    return (...)
})

// 4. Virtualization for long lists
<FixedSizeList
    height={600}
    itemCount={1000}
    itemSize={50}
>
    {renderItem}
</FixedSizeList>

// 5. Debounced Search
const [searchQuery, setSearchQuery] = useState('')
const debouncedSearch = useMemo(
    () => debounce((query) => performSearch(query), 300),
    []
)
```

### **Backend Optimizations**

```python
# 1. Async/Await (Non-blocking I/O)
async def handle_chat(data):
    # Doesn't block other requests
    await db_service.create_message(...)
    await langgraph_service.process(...)

# 2. Task Cancellation
task = asyncio.create_task(process_chat())
add_stream_task(session_id, task)
# Can cancel: task.cancel()

# 3. Connection Pooling
async with aiosqlite.connect(db_path) as db:
    # Connection reused

# 4. Caching
from functools import lru_cache

@lru_cache(maxsize=128)
def get_model_config(model_name):
    # Cached across requests
    return load_model_config(model_name)
```

---

## ðŸŽ¯ Request Flow: Complete Example

### **User generates an image**

```
1. FRONTEND
   â””â”€ User types: "Generate a sunset landscape"
   â””â”€ Selects: GPT-4 (text) + Flux (image)
   â””â”€ Clicks: "Generate"

2. HTTP REQUEST
   POST /api/chat
   {
     messages: [{role: 'user', content: 'Generate a sunset...'}],
     session_id: 'sess_xyz',
     text_model: {model: 'gpt-4', provider: 'openai'},
     tool_list: [{model: 'flux', provider: 'comfyui'}]
   }

3. BACKEND PROCESSING
   a) chat_router receives request
   b) chat_service.handle_chat(data)
   c) db_service.create_chat_session(session_id)
   d) db_service.create_message(session_id, 'user', message)
   e) asyncio.create_task(langgraph_multi_agent(...))

4. AI ORCHESTRATION
   a) langgraph_multi_agent creates LLM (ChatOpenAI)
   b) Loads tools (Flux image generation)
   c) Builds agent graph
   d) Runs: agent.stream_events()
   
   Events stream:
   â”œâ”€ on_chat_model_stream: "I'll generate a beautiful sunset..."
   â”œâ”€ on_tool_start: "Calling Flux..."
   â”œâ”€ on_tool_stream: <image generation progress>
   â”œâ”€ on_tool_end: "Image generated: https://..."
   â””â”€ on_chat_model_stream: "Here's your sunset image!"

5. REAL-TIME WEBSOCKET UPDATES
   For each event:
   â””â”€ await send_to_websocket(session_id, {
        type: 'token',
        delta: 'word'
      })

6. FRONTEND RECEIVES UPDATES
   socket.on('session_update', (data) => {
     if (data.type === 'token') {
       setOutput(prev => prev + data.delta)
     }
   })

7. DATABASE PERSISTENCE
   â””â”€ db_service.create_message(session_id, 'assistant', full_response)

8. COMPLETION
   â””â”€ send_to_websocket(session_id, { type: 'done' })
   â””â”€ Frontend stops loading spinner
   â””â”€ Display full result with image
```

---

## ðŸŽ‰ Summary: What Makes It Work

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Frontend** | React 19 + Vite | User interface & interactions |
| **State** | Zustand | Client-side state management |
| **Animations** | Framer Motion | Smooth, performant animations |
| **Styling** | Tailwind CSS | Utility-first design system |
| **Backend** | FastAPI | High-performance async API |
| **Real-time** | Socket.IO | WebSocket communication |
| **AI Orchestration** | LangGraph | Multi-agent workflow engine |
| **LLMs** | OpenAI, Anthropic | Language models |
| **Image Gen** | Flux, ComfyUI | Image generation |
| **Database** | SQLite + aiosqlite | Async data persistence |
| **Payments** | Stripe | Payment processing |
| **Containers** | Docker | Production deployment |
| **Reverse Proxy** | Nginx (via Coolify) | Load balancing & SSL |

**Result**: A fully functional, production-ready AI canvas application with real-time streaming, multiple AI providers, payment processing, and beautiful animations! ðŸš€
